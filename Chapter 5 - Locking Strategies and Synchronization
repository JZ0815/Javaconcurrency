## Chapter 5: Concurrency Control: Locking Strategies and Synchronization

### 5.1 Pessimistic Locking

#### 5.1.1 Concept and Characteristics
Pessimistic locking opeConcurrency Control: Locking Strategies and Synchronizationrates under the assumption that concurrent access conflicts are inevitable. When a thread accesses shared data, it immediately acquires a lock to prevent other threads from modifying the data simultaneously. This approach ensures data consistency by enforcing exclusive access during critical sections.

Key characteristics:
- **Preemptive locking**: Locks are acquired before any data access
- **Exclusive access**: Only one thread can operate on the locked resource at a time
- **Blocking behavior**: Other threads must wait until the lock is released
- **Strong consistency**: Guarantees data integrity during write operations

#### 5.1.2 Implementation Methods
Java provides two primary implementations of pessimistic locking:

1. **synchronized keyword**
   - Built-in language feature
   - Automatic lock release
   - Method-level or block-level synchronization
   - Reentrant capability

2. **Lock interface implementations**
   - More flexible than synchronized
   - Explicit lock/unlock control
   - Supports tryLock() with timeout
   - Condition variables for precise thread signaling

#### 5.1.3 Code Examples

#### Synchronized Method Example
```java
public class SynchronizedExample {
    private int counter = 0;
    
    // Method-level synchronization
    public synchronized void increment() {
        counter++;
        // Additional operations...
    }
    
    // Block-level synchronization
    public void performOperation() {
        // Non-critical section code
        
        synchronized(this) {
            // Critical section code
            counter--;
        }
        
        // More non-critical section code
    }
}
```

#### ReentrantLock Example
```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class LockExample {
    private final Lock lock = new ReentrantLock();
    private int sharedResource = 0;
    
    public void modifyResource() {
        lock.lock();  // Acquire the lock
        try {
            // Critical section
            sharedResource++;
            // Complex operations...
        } finally {
            lock.unlock();  // Ensure lock is released
        }
    }
    
    public boolean tryModifyWithTimeout() {
        try {
            if (lock.tryLock(1, TimeUnit.SECONDS)) {
                try {
                    // Operation protected by lock
                    sharedResource--;
                    return true;
                } finally {
                    lock.unlock();
                }
            }
            return false;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return false;
        }
    }
}
```

#### 5.1.4 Use Cases and Considerations
Pessimistic locking is particularly suitable for:
- **Write-heavy scenarios** where data contention is frequent
- **Critical financial operations** requiring absolute consistency
- **Long-running transactions** that cannot tolerate interference
- **Legacy systems** where optimistic approaches aren't feasible

Performance considerations:
- May lead to **deadlocks** if not managed carefully
- Can cause **thread contention** in high-concurrency scenarios
- **Overhead** increases with lock granularity
- Potential for **reduced throughput** under heavy contention

### 5.2 Optimistic Locking

#### 5.2.1 Concept and Characteristics
Optimistic locking operates on the assumption that conflicts are rare. Instead of locking resources upfront, it allows concurrent access and only verifies for conflicts during updates. This approach maximizes system throughput by minimizing locking overhead.

Key characteristics:
- **No upfront locking**: Threads access data without initial restrictions
- **Conflict detection**: Checks for modifications before committing changes
- **Non-blocking**: Threads don't wait unless retrying after conflict
- **High throughput**: Ideal for read-dominated workloads

#### 5.2.2 Implementation Methods

#### Version Number Mechanism
- Each data record maintains a version number
- Before update, compare current version with original read version
- Increment version on successful update
- Reject updates with version mismatch

#### CAS (Compare-And-Swap) Algorithm
- Atomic operation comparing current value with expected value
- Updates only if comparison matches
- No locking required at hardware level
- May suffer from ABA problem (solved with versioning)

#### 5.2.3 Code Examples

#### Atomic Variables Example
```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicExample {
    private AtomicInteger counter = new AtomicInteger(0);
    
    public void safeIncrement() {
        // Atomic increment
        counter.incrementAndGet();
        
        // Complex CAS operation
        int expected, newValue;
        do {
            expected = counter.get();
            newValue = expected * 2;
        } while (!counter.compareAndSet(expected, newValue));
    }
}
```

#### Version Control Example
```java
public class VersionedRecord {
    private int data;
    private int version;
    
    public synchronized void update(int newData, int expectedVersion) throws StaleDataException {
        if (this.version != expectedVersion) {
            throw new StaleDataException("Version conflict detected");
        }
        this.data = newData;
        this.version++;
    }
    
    // Getters omitted for brevity
}
```

#### 5.2.4 Use Cases and Considerations
Optimistic locking excels in:
- **Read-dominated workloads** with infrequent writes
- **High-concurrency systems** where contention is rare
- **Distributed systems** where locking is expensive
- **Performance-critical applications** requiring low latency

Implementation challenges:
- **ABA problem**: Requires version numbers or additional markers
- **Retry overhead**: Conflicts may require operation repetition
- **Stale reads**: Temporary inconsistency between read and update
- **Complex recovery**: Need to handle failed updates gracefully

#### 5.2.5 Performance Comparison

| Aspect              | Pessimistic Locking | Optimistic Locking |
|---------------------|---------------------|--------------------|
| **Contention**      | High                | Low                |
| **Overhead**        | Higher              | Lower              |
| **Throughput**      | Lower under load    | Higher under load  |
| **Consistency**     | Strong              | Eventual           |
| **Best For**        | Write-heavy         | Read-heavy         |
| **Complexity**      | Lower               | Higher             |

### 5.3 Choosing the Right Locking Strategy

#### 5.3.1 Decision Factors
1. **Read/Write Ratio**: Optimistic for read-heavy, pessimistic for write-heavy
2. **Contention Likelihood**: High contention favors pessimistic approaches
3. **Performance Requirements**: Optimistic offers better throughput
4. **Data Criticality**: Pessimistic ensures stronger consistency
5. **System Architecture**: Distributed systems often prefer optimistic

#### 5.3.2 Hybrid Approaches
Modern systems often combine both strategies:
- **Optimistic reads** with **pessimistic writes**
- **Pessimistic coarse-grained** locks with **optimistic fine-grained** controls
- **Optimistic** conflict detection with **pessimistic** fallback mechanisms

Example hybrid implementation:
```java
public class HybridLockingExample {
    private final ReentrantLock writeLock = new ReentrantLock();
    private final AtomicInteger version = new AtomicInteger(0);
    private Object data;
    
    public Object readData() {
        // Optimistic read
        int currentVersion = version.get();
        Object localCopy = data;
        if (version.get() == currentVersion) {
            return localCopy;
        }
        // Version changed during read, retry with pessimistic lock
        writeLock.lock();
        try {
            return data;
        } finally {
            writeLock.unlock();
        }
    }
    
    public void updateData(Object newData) {
        writeLock.lock();
        try {
            // Pessimistic write
            data = newData;
            version.incrementAndGet();
        } finally {
            writeLock.unlock();
        }
    }
}
```
### 5.4

### 5.5 Fair Locks vs. Non-fair Locks

#### 5.5.1 Ticket Sales Demo Illustrating Fair and Non-fair Behavior

```java

import java.util.concurrent.locks.ReentrantLock;

class Ticket {
    private int number = 30;
    ReentrantLock lock = new ReentrantLock(); // Defaults to non-fair lock
    
    public void sale() {
        lock.lock();
        try {
            if(number > 0) {
                System.out.println(Thread.currentThread().getName()+" sold ticket #"+(number--)+", remaining:"+number);
            }
        } finally {
            lock.unlock();
        }
    }
}

public class TicketSalesDemo {
    public static void main(String[] args) {
        Ticket ticket = new Ticket();
        
        new Thread(() -> { 
            for (int i = 0; i < 35; i++) ticket.sale(); 
        }, "Seller-A").start();
        
        new Thread(() -> { 
            for (int i = 0; i < 35; i++) ticket.sale(); 
        }, "Seller-B").start();
        
        new Thread(() -> { 
            for (int i = 0; i < 35; i++) ticket.sale(); 
        }, "Seller-C").start();
    }
}
```

#### 5.5.2 Understanding Fair and Non-fair Locks

Lock fairness refers to whether threads acquire locks in the exact order they requested them (FIFO principle):
- **Fair Lock**: Strictly grants locks in request arrival order
- **Non-fair Lock**: Allows thread "cutting in line" to acquire locks

**Implementation Mechanism**:
- Fair locks check the synchronization queue for waiting threads before acquisition
- Non-fair locks attempt immediate acquisition regardless of queue status

**Why is non-fair locking the default design?**
   - Performance optimization: Reduces thread context switching overhead
   - CPU utilization: Minimizes CPU idle time caused by strict queuing
   - Thread locality: Recently released threads have higher chance of re-acquisition

**Potential issues with fair locks**
   - Thread starvation: Some threads may wait indefinitely
   - Throughput degradation: Strict queuing increases switching costs
   - Unpredictable latency: Queue position determines wait time

**Lock selection strategy**
   - Prefer non-fair locks for: High-throughput systems, performance-critical sections
   - Choose fair locks when: Thread fairness is business-critical, avoiding starvation is required

**Important Notes**:
- Fairness only affects lock acquisition order, not thread scheduling
- Non-fair locks may show thread barging (same thread acquiring consecutively)
- Actual performance characteristics are JVM implementation dependent
- Always validate lock choice through benchmarking for your specific use case

**Practical Considerations**:
- Modern JVMs optimize for non-fair locking scenarios
- Fair locks add ~5-10% overhead in contended situations
- Consider ReadWriteLock for read-heavy scenarios
- Synchronized blocks are intrinsically non-fair in Java

### 5.6 Reentrant Locks (Recursive Locks)

#### 5.6.1 Concept Explanation

A reentrant lock (also called recursive lock) allows the same thread to acquire the lock multiple times without deadlocking. When a thread holds a lock on an object, it can re-enter any synchronized block/method protected by that same lock object.

Key characteristics:
- Automatic lock acquisition for nested method calls
- Prevents self-blocking scenarios
- Both `ReentrantLock` and `synchronized` in Java are reentrant
- Helps avoid certain deadlock situations

**Etymology of "Reentrant Lock":**
- Re: Again
- Entrant: Entering
- Lock: Synchronization mechanism
- Meaning: A thread can re-enter synchronized sections protected by a lock it already holds

#### 5.6.2 Types of Reentrant Locks

**Implicit Locks (synchronized)**
   - Built-in reentrant capability
   - Allows recursive synchronization
   - Example of non-reentrant lock behavior would cause immediate deadlock for recursive calls

```java
// Synchronized block example
public class ReentryLockDemo {
    public static void main(String[] args) {
        final Object lock = new Object();
        
        new Thread(() -> {
            synchronized(lock) {
                System.out.println("Outer lock");
                synchronized(lock) {
                    System.out.println("Middle lock");
                    synchronized(lock) {
                        System.out.println("Inner lock");
                    }
                }
            }
        }).start();
    }
}
```

```java
// Synchronized method example
public class ReentryLockDemo {
    public synchronized void m1() {
        System.out.println("m1");
        m2();
    }
    
    public synchronized void m2() {
        System.out.println("m2");
        m3();
    }
    
    public synchronized void m3() {
        System.out.println("m3");
    }
    
    public static void main(String[] args) {
        new ReentryLockDemo().m1();
    }
}
```

**Implementation Mechanism:**
- Each lock object maintains:
  - A counter tracking acquisition count
  - Pointer to the owning thread
- When entering synchronized block (`monitorenter`):
  - If counter=0: Set owner thread, increment counter
  - If owned by current thread: Increment counter
  - Otherwise: Thread blocks
- When exiting (`monitorexit`): Decrement counter (lock released at 0)

**Explicit Locks (ReentrantLock)**
   - Programmatically managed reentrancy
   - Must match lock/unlock pairs
   - Example showing improper unlock counting:

```java
public class ReentryLockDemo {
    static Lock lock = new ReentrantLock();
    
    public static void main(String[] args) {
        new Thread(() -> {
            lock.lock();
            try {
                System.out.println("Outer lock");
                lock.lock();
                try {
                    System.out.println("Inner lock");
                } finally {
                    // Missing unlock (intentional bug)
                }
            } finally {
                lock.unlock();
            }
        }).start();
        
        new Thread(() -> {
            lock.lock(); // Will block indefinitely
            try {
                System.out.println("Second thread");
            } finally {
                lock.unlock();
            }
        }).start();
    }
}
```
**Why Reentrancy Matters:**
   - Enables recursive method calls
   - Allows synchronized methods to call other synchronized methods
   - Prevents single-thread deadlocks

**Implementation Considerations:**
   - Synchronized blocks use object monitors
   - ReentrantLock maintains separate acquisition count
   - Unbalanced lock/unlock operations cause thread starvation

**Best Practices:**
   - Always use try-finally with explicit locks
   - Match lock/unlock pairs exactly
   - Prefer synchronized blocks for simple cases
   - Use ReentrantLock for advanced features (timed waits, fairness)

**Performance Characteristics:**
   - Reentrant operations are fast-path optimized
   - Modern JVMs optimize reentrant synchronization
   - Contended reentrant locks still incur performance costs
   Here's the rewritten version of section 5.7 in English:


### 5.7 Deadlocks and Diagnostics

#### 5.7.1 Understanding Deadlocks

A deadlock occurs when two or more threads are blocked indefinitely, each waiting for resources held by the other threads in the cycle. This creates a permanent blocking state unless external intervention occurs.

**Primary Causes:**
1. **Resource Scarcity**: Insufficient system resources forcing contention
2. **Improper Execution Sequence**: Threads requesting resources in conflicting orders
3. **Poor Resource Allocation**: Resources granted without considering dependency chains

#### 5.7.2 Deadlock Demonstration Case

```java
public class DeadlockDemo {
    private static final Object lockA = new Object();
    private static final Object lockB = new Object();

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized(lockA) {
                System.out.println(Thread.currentThread().getName() 
                    + " holds lockA, requesting lockB");
                try { 
                    Thread.sleep(1000); // Intentional delay to trigger deadlock
                } catch (InterruptedException e) { /* handle */ }
                
                synchronized(lockB) {
                    System.out.println("ThreadA acquired both locks");
                }
            }
        }, "Thread-A").start();

        new Thread(() -> {
            synchronized(lockB) {
                System.out.println(Thread.currentThread().getName() 
                    + " holds lockB, requesting lockA");
                try { 
                    Thread.sleep(1000); 
                } catch (InterruptedException e) { /* handle */ }
                
                synchronized(lockA) {
                    System.out.println("ThreadB acquired both locks");
                }
            }
        }, "Thread-B").start();
    }
}
```

**Deadlock Conditions Met:**
1. **Mutual Exclusion**: Only one thread can hold each lock
2. **Hold and Wait**: Threads keep held locks while requesting others
3. **No Preemption**: Cannot force release of acquired locks
4. **Circular Wait**: Thread-A waits for Thread-B which waits for Thread-A

#### 5.7.3 Deadlock Detection Methods

**Command Line Tools:**
1. List Java processes:
   ```bash
   jps -l
   ```
2. Get thread dump:
   ```bash
   jstack <process_id>
   ```
   Sample deadlock detection output:
   ```
   Found one Java-level deadlock:
   =============================
   "Thread-B":
     waiting to lock monitor 0x00007f... (object 0x000000076ab...)
     which is held by "Thread-A"
   "Thread-A":
     waiting to lock monitor 0x00007f... (object 0x000000076ab...)
     which is held by "Thread-B"
   ```

**GUI Tools:**
- **JConsole**: Visual thread monitoring with deadlock detection tab
- **VisualVM**: Advanced thread analysis with deadlock identification
- **JMC (Java Mission Control)**: Production-grade diagnostic tool

**Prevention Strategies:**
1. **Lock Ordering**: Always acquire locks in consistent global order
2. **Timeout Mechanisms**: Use `tryLock()` with timeouts
3. **Deadlock Detection**: Implement watchdog threads
4. **Resource Hierarchy**: Define strict resource acquisition sequences

**Debugging Tips:**
1. Reproduce with deterministic delays
2. Analyze thread dumps during hangs
3. Monitor with `-XX:+PrintGCDetails -XX:+PrintConcurrentLocks`
4. Use IDE debugger's thread inspection

### 5.8 Lock Optimization Progression

#### 5.8.1 Write (Exclusive) vs Read (Shared) Locks
*For in-depth implementation analysis, see Chapter 15*

- **Exclusive Locks (Write)**: Single-writer principle
- **Shared Locks (Read)**: Multiple concurrent readers
- Key tradeoff: Consistency vs concurrency

#### 5.8.2 Spin Lock Fundamentals
*Implementation details covered in Chapter 9*

Characteristics:
- Busy-waiting instead of thread suspension
- Optimal for short critical sections
- CPU-intensive but avoids context switching
- Common CAS (Compare-And-Swap) implementation

#### 5.8.3 Lock Evolution Path
*Full analysis in Chapter 13*

1. **No Lock**: Baseline performance
2. **Exclusive Lock**: Simplest thread safety
3. **ReadWriteLock**: Reader/writer separation
4. **StampedLock**: Advanced optimistic locking

**StampedLock Advantages**:
- Optimistic read operations
- Upgradeable read locks
- Lower contention overhead
- Combines best features of previous locks

#### 5.8.4 Synchronization State Progression
*See Chapter 12 for JVM internals*

Lock escalation path:
1. **No Lock**: Uncontended
2. **Biased Lock**: Single-thread optimization
3. **Thin Lock**: Lightweight contention
4. **Fat Lock**: Full monitor contention

#### 5.8.5 Critical Anti-Patterns

**String Lock Hazard**:
```java
// Dangerous practice - never do this!
synchronized(lockString.intern()) {
    // Critical section
}
```

Why prohibited:
- String pool pollution risk
- Unpredictable lock scope
- Potential deadlocks from JVM string deduplication
- Use dedicated lock objects instead

**Recommended Alternatives**:
```java
// Proper solutions
private final Object explicitLock = new Object();
private final ReentrantLock jucLock = new ReentrantLock();
```
{pagebreak}


