## Chapter 2: Concurrent Collections and Core Concurrency Utilities

### 2.1 Overview

The `java.util.concurrent` package is a cornerstone of Java’s concurrency utilities, providing a robust toolkit to manage multi-threaded applications efficiently. Whether you're coordinating threads, managing task execution, or synchronizing access to shared resources, this package offers powerful abstractions and implementations.

In this chapter, we’ll provide an overview of the major components within this package, highlight some key concepts, and prepare the ground for more in-depth discussions on executors and asynchronous programming in the following chapters.


### 2.2 Main Components of `java.util.concurrent`

The `java.util.concurrent` package is vast. It offers interfaces, classes, and utilities tailored for high-level thread management, synchronization, and communication. Below are some of the most important components we'll cover:

- **Executor Framework** (`Executor`, `ExecutorService`, `ScheduledExecutorService`)
- **Asynchronous Task Handling** (`Future`, `Callable`)
- **Synchronization Utilities** (`CountDownLatch`, `CyclicBarrier`, `Semaphore`, `Phaser`)
- **Advanced Collections** (`BlockingQueue`, `DelayQueue`)
- **Custom Thread Control** (`ThreadFactory`, `Locks`)

In the following sections, we will briefly introduce `ExecutorService`, `ScheduledExecutorService`, and `Future`, and leave the detailed exploration for **Chapter 3** and **Chapter 4**.


### 2.3 Executor

The `Executor` interface provides a simple abstraction for decoupling task submission from the mechanics of how each task will be executed. Rather than manually starting threads, you simply provide tasks to an `Executor` implementation, and it takes care of running them.

```java
public class Invoker implements Executor {
    @Override
    public void execute(Runnable r) {
        r.run();
    }
}
```

You can use this `Invoker` as:

```java
Executor executor = new Invoker();
executor.execute(() -> {
    // task logic
});
```

> Note: The `Executor` interface does not guarantee asynchronous execution. It merely defines a contract for running tasks.


### 2.4 ExecutorService

The `ExecutorService` extends `Executor` and introduces a full-fledged API for managing task lifecycles and thread pools. It handles task queuing, scheduling, and graceful shutdown of worker threads.

Here’s a quick preview:

```java
ExecutorService executor = Executors.newFixedThreadPool(10);
executor.submit(() -> {
    // task logic
});
executor.shutdown();
```

It offers more advanced methods such as `shutdownNow()` and `awaitTermination(...)` for managing thread lifecycles. We'll dive deep into thread pooling strategies and best practices in **Chapter 3**.


### 2.5 ScheduledExecutorService

`ScheduledExecutorService` is similar to `ExecutorService` but supports scheduling tasks to run after a delay or at fixed intervals. This is especially useful for periodic or delayed tasks.

```java
ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
scheduler.schedule(() -> {
    System.out.println("Task executed with delay");
}, 1, TimeUnit.SECONDS);
```

### 2.6 Future

The `Future` interface represents the result of an asynchronous computation. It provides methods to check completion, cancel execution, and retrieve the result:

```java
Future<String> future = executor.submit(() -> {
    Thread.sleep(1000);
    return "Hello";
});
```

You can later retrieve the result:

```java
if (future.isDone()) {
    String result = future.get();
}
```

Exception handling and timeout management are key aspects, which we’ll explore thoroughly in **Chapter 4**.


### 2.7 CountDownLatch  

`CountDownLatch` is a synchronization aid that allows threads to wait until a set of operations completes. It is initialized with a specified **count**, which is decremented by threads using the `countDown()` method. Threads calling `await()` will block until the count reaches zero, after which they are released.  

#### Key Methods of `CountDownLatch`
- **`await()`**  
  - Causes the current thread to wait until the latch count reaches zero, unless interrupted.  
  ```java
  public void await() throws InterruptedException {
      sync.acquireSharedInterruptibly(1);
  }
  ```  

- **`countDown()`**  
  - Decrements the latch’s count. If the count reaches zero, all waiting threads are released.  
  ```java
  public void countDown() {
      sync.releaseShared(1);
  }
  ```  


### Example Without `CountDownLatch`  
The following code simulates six students leaving a classroom, with the monitor locking the door afterward. Without synchronization, the output is unpredictable—the monitor may lock the door before all students exit.  

```java
public class CountDownLatchTest {
    public static void main(String[] args) throws InterruptedException {
        for (int i = 1; i <= 6; i++) {
            new Thread(() -> {
                System.out.println(Thread.currentThread().getName() + " leaves the classroom");
            }, String.valueOf(i)).start();
        }
        System.out.println(Thread.currentThread().getName() + " locks the door");
    }
}
```  

**Possible Output (Unordered Execution):**  
```
2 leaves the classroom  
6 leaves the classroom  
5 leaves the classroom  
4 leaves the classroom  
1 leaves the classroom  
main locks the door  
3 leaves the classroom  
```  
Here, the door is locked prematurely while some students are still leaving.  


### Example With `CountDownLatch`  
Using `CountDownLatch`, we ensure the monitor locks the door **only after all students have left**.  

```java
public class CountDownLatchTest {
    public static void main(String[] args) throws InterruptedException {
        CountDownLatch countDownLatch = new CountDownLatch(6); // Initialize with 6 students
        for (int i = 1; i <= 6; i++) {
            new Thread(() -> {
                System.out.println(Thread.currentThread().getName() + " leaves the classroom");
                countDownLatch.countDown(); // Decrement count
            }, String.valueOf(i)).start();
        }
        countDownLatch.await(); // Wait until count reaches 0
        System.out.println(Thread.currentThread().getName() + " locks the door");
    }
}
```  

**Expected Output (Ordered Execution):**  
```
1 leaves the classroom  
2 leaves the classroom  
3 leaves the classroom  
4 leaves the classroom  
5 leaves the classroom  
6 leaves the classroom  
main locks the door  
```  
Now, the monitor locks the door only after all students have exited.  


### 2.8 CyclicBarrier 

`CyclicBarrier` is a synchronization mechanism that allows a group of threads to wait for each other until they all reach a common execution point (the *barrier*). Once all threads arrive, a predefined action (if specified) is executed, and the barrier resets, making it reusable for subsequent operations.  

#### Key Features  
- **Reusable Barrier**: Unlike `CountDownLatch`, `CyclicBarrier` can be reset and reused after all threads pass through.  
- **Optional Barrier Action**: A `Runnable` can be triggered once all threads reach the barrier.  

#### Constructor  
```java
CyclicBarrier(int parties, Runnable barrierAction)  
```  
- **`parties`**: Number of threads that must invoke `await()` before the barrier opens.  
- **`barrierAction`**: (Optional) A task executed once all threads reach the barrier.  

#### Core Method  
- **`await()`**  
  - Blocks the current thread until all threads reach the barrier.  
  - Returns the arrival index of the thread (useful for post-barrier logic).  
  - Throws `InterruptedException` or `BrokenBarrierException` if interrupted or the barrier fails.  

  ```java
  public int await() throws InterruptedException, BrokenBarrierException {
      try {
          return dowait(false, 0L);
      } catch (TimeoutException toe) {
          throw new Error(toe);
      }
  }
  ```  

### Example: Collecting Dragon Balls  
In this scenario, 7 threads (representing Dragon Balls) must be collected before summoning the Dragon. The barrier action triggers only after all threads complete.  

#### Code Implementation  
```java
public class CyclicBarrierTest {
    private static final int NUMBER = 7; // Total Dragon Balls needed
    
    public static void main(String[] args) {
        // Create a barrier for 7 threads with a summoning action
        CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, () -> {
            System.out.println("**** All 7 Dragon Balls collected! Summoning the Dragon ****");
        });
        
        // Simulate collecting each Dragon Ball in separate threads
        for (int i = 1; i <= NUMBER; i++) {
            new Thread(() -> {
                System.out.println(Thread.currentThread().getName() + " → Dragon Ball collected");
                try {
                    cyclicBarrier.await(); // Wait for all 7 threads
                } catch (InterruptedException | BrokenBarrierException e) {
                    e.printStackTrace();
                }
            }, String.valueOf(i)).start();
        }
    }
}
```  

#### Output  
Thread execution order may vary, but the barrier action runs **only after all 7 threads arrive**:  
```
3 → Dragon Ball collected  
5 → Dragon Ball collected  
1 → Dragon Ball collected  
6 → Dragon Ball collected  
2 → Dragon Ball collected  
4 → Dragon Ball collected  
7 → Dragon Ball collected  
**** All 7 Dragon Balls collected! Summoning the Dragon ****
```  


### Key Takeaways 
1. **Synchronization**: Ensures threads proceed only after reaching a common point.  
2. **Reusability**: The barrier resets automatically for future use.  
3. **Practical Use Cases**:  
   - Parallel computation (e.g., merging results after all subtasks finish).  
   - Multiplayer games (e.g., starting a round only when all players are ready).  
### 2.9 Semaphore

A **Semaphore** is a synchronization tool that controls access to shared resources by maintaining a limited number of permits. Threads must acquire a permit before accessing the resource and release it afterward, ensuring controlled concurrency.

#### Key Features
- **Permit-Based Access**: Limits the number of concurrent threads accessing a resource.
- **Fairness Option**: Can be configured to grant permits in FIFO order (fair mode) or allow barging (non-fair mode).
- **Flexible Usage**: Useful for resource pools (e.g., database connections, thread pools).


### Core Methods
#### Constructor
```java
Semaphore(int permits)
```
- Creates a semaphore with the specified number of permits (non-fair by default).

#### Critical Methods
1. **`acquire()`**  
   - Requests a permit. Blocks until one is available or the thread is interrupted.  
   ```java
   public void acquire() throws InterruptedException {
       sync.acquireSharedInterruptibly(1);
   }
   ```

2. release()`  
   - Releases a permit back to the semaphore, allowing other threads to proceed.  
   ```java
   public void release() {
       sync.releaseShared(1);
   }
   ```

### Practical Example: Parking Lot Simulation
A parking lot with **3 spaces** shared among **6 cars** demonstrates semaphore usage:
- Each "car" (thread) must acquire a permit (parking spot) before entering.
- If all spots are taken, cars wait until one becomes available.
- When a car leaves, it releases the permit for others.

#### Implementation
```java
public class SemaphoreTest {
    public static void main(String[] args) {
        Semaphore parkingLot = new Semaphore(3); // 3 parking spots
        
        for (int i = 1; i <= 6; i++) {
            new Thread(() -> {
                try {
                    parkingLot.acquire(); // Request a spot
                    System.out.println(Thread.currentThread().getName() + " parks in a spot.");
                    
                    // Simulate random parking duration
                    TimeUnit.SECONDS.sleep(new Random().nextInt(5));
                    
                    System.out.println(Thread.currentThread().getName() + " leaves the spot.");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    parkingLot.release(); // Free the spot
                }
            }, "Car " + i).start();
        }
    }
}
```

#### Sample Output
```
Car 1 parks in a spot.
Car 2 parks in a spot.
Car 3 parks in a spot.
Car 2 leaves the spot.
Car 4 parks in a spot.
Car 1 leaves the spot.
Car 5 parks in a spot.
Car 3 leaves the spot.
Car 6 parks in a spot.
...
```
**Behavior**:  
- Only **3 cars** can park simultaneously.  
- As cars leave, waiting cars immediately take the freed spots.  

### Key Takeaways
1. **Concurrency Control**: Semaphores enforce limits on resource access.  
2. **Resource Management**: Ideal for scenarios like connection pooling or throttling.  
3. **Versatility**: Supports both blocking (`acquire()`) and non-blocking (`tryAcquire()`) operations.  


### 2.10 ThreadFactory

`ThreadFactory` abstracts thread creation. Custom factories help create named threads or threads with specific configurations (priority, daemon status, etc.)

```java
public class NamedThreadFactory implements ThreadFactory {
    private int count = 0;
    public Thread newThread(Runnable r) {
        return new Thread(r, "CustomThread-" + count++);
    }
}
```

Use this to plug into thread pools for better debugging and monitoring.

### 2.13 BlockingQueue

BlockingQueue is a thread-safe queue implementation designed for producer-consumer scenarios. It provides blocking operations that wait for the queue to become non-empty when retrieving elements and non-full when storing elements.

#### Core Characteristics
- Thread-safe concurrent access
- Blocking operations for flow control
- Support for timeout-based operations
- Multiple implementation strategies

### Primary Implementations

| Implementation | Key Features |
|----------------|--------------|
| ArrayBlockingQueue | Fixed capacity, array-backed, single lock |
| LinkedBlockingQueue | Optional capacity, higher throughput |
| PriorityBlockingQueue | Unbounded, priority ordering |
| DelayQueue | Time-delayed element retrieval |
| SynchronousQueue | Direct handoff without buffering |

### Core Operations

| Operation | Behavior |
|-----------|----------|
| add(e) | Throws exception if queue is full |
| offer(e) | Returns false if queue is full |
| put(e) | Blocks if queue is full |
| remove() | Throws exception if queue is empty |
| poll() | Returns null if queue is empty |
| take() | Blocks if queue is empty |

### Usage Examples

#### Basic Producer-Consumer Pattern
```java
BlockingQueue<Integer> queue = new ArrayBlockingQueue<>(5);

// Producer thread
new Thread(() -> {
    try {
        for (int i = 0; i < 10; i++) {
            queue.put(i); // Blocks if queue is full
            System.out.println("Produced: " + i);
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}).start();

// Consumer thread
new Thread(() -> {
    try {
        for (int i = 0; i < 10; i++) {
            Integer value = queue.take(); // Blocks if queue is empty
            System.out.println("Consumed: " + value);
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}).start();
```
This example shows a classic producer-consumer pattern. The producer puts integers into the queue, while the consumer takes them out. Both operations will block appropriately when the queue is full or empty, demonstrating the core functionality of BlockingQueue.

#### Priority-Based Processing
```java
BlockingQueue<String> queue = new PriorityBlockingQueue<>();

// Add elements out of order
queue.put("Orange");
queue.put("Apple");
queue.put("Banana");

// Will be retrieved in alphabetical order
System.out.println(queue.take()); // Apple
System.out.println(queue.take()); // Banana 
System.out.println(queue.take()); // Orange
```
PriorityBlockingQueue orders elements according to their natural ordering (or a Comparator). This example shows how elements are retrieved in sorted order regardless of insertion order, which is useful for priority-based task processing.

#### Timeout Handling
```java
BlockingQueue<String> queue = new ArrayBlockingQueue<>(1);

// First offer succeeds
boolean success1 = queue.offer("First", 1, TimeUnit.SECONDS);
System.out.println(success1); // true

// Second offer waits for 1 second then fails
boolean success2 = queue.offer("Second", 1, TimeUnit.SECONDS); 
System.out.println(success2); // false
```
This demonstrates how to use the timeout version of offer(). When the queue is full, it will wait for the specified time (1 second in this case) before giving up, allowing for graceful degradation in busy systems.

#### Synchronous Handoff
```java
BlockingQueue<String> queue = new SynchronousQueue<>();

// Producer
new Thread(() -> {
    try {
        String data = "Important Message";
        queue.put(data); // Waits for consumer to take
        System.out.println("Message delivered");
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}).start();

// Consumer
new Thread(() -> {
    try {
        Thread.sleep(1000); // Simulate processing delay
        String received = queue.take();
        System.out.println("Received: " + received);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}).start();
```
SynchronousQueue is a special implementation that doesn't store elements but instead facilitates direct handoff between threads. This example shows how it can be used for tight coordination between producers and consumers.

#### Graceful Shutdown
```java
BlockingQueue<String> queue = new LinkedBlockingQueue<>();
queue.add("Task1");
queue.add("Task2");

// Poison pill pattern
queue.add("STOP"); 

while (true) {
    try {
        String task = queue.take();
        if (task.equals("STOP")) {
            break;
        }
        System.out.println("Processing: " + task);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}
```
This demonstrates a common pattern for graceful shutdown using a special "poison pill" value. When the consumer encounters this value, it knows to stop processing, allowing for clean shutdown of worker threads.


### 2.14 DelayQueue

`DelayQueue` is a specialized blocking queue in Java that holds elements until a specific delay time has passed. It is often used for scheduling tasks, expiring cache entries, or throttling operations. The elements stored must implement the `Delayed` interface, which defines how long an item should remain in the queue before becoming available.

#### Key Features

- **Unbounded capacity** – There is no upper limit on the number of elements; the queue can grow as needed.
- **Thread-safe** – Supports concurrent insertion and retrieval from multiple threads without requiring external synchronization.
- **Priority-based** – Internally uses a priority queue to order elements based on their remaining delay time; the one with the shortest time comes out first.
- **Blocking operations** – Retrieval methods like `take()` will block until an element's delay has expired, ensuring items are only consumed when ready.


#### **Implementing Delayed Elements**

To use `DelayQueue`, you must define the delay logic by implementing the `Delayed` interface. This involves specifying how much time remains before an element becomes available.

```java
class DelayedItem implements Delayed {
    private String data;
    private long expiryTime;
    
    DelayedItem(String data, long delayMs) {
        this.data = data;
        this.expiryTime = System.nanoTime() + 
                         TimeUnit.NANOSECONDS.convert(delayMs, TimeUnit.MILLISECONDS);
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return unit.convert(expiryTime - System.nanoTime(), TimeUnit.NANOSECONDS);
    }

    @Override
    public int compareTo(Delayed other) {
        return Long.compare(expiryTime, ((DelayedItem)other).expiryTime);
    }

    @Override
    public String toString() {
        return data;
    }
}
```

- `getDelay()` tells the queue how much longer the item should be delayed.
- `compareTo()` determines the order in the queue based on expiration time.
- `System.nanoTime()` is preferred for time comparisons because it’s not affected by system clock changes.

#### **Using the Queue**

Here's how you can use `DelayQueue` to schedule delayed processing:

```java
DelayQueue<DelayedItem> queue = new DelayQueue<>();

// Add elements with different delays
queue.put(new DelayedItem("A", 2000));  // 2 second delay
queue.put(new DelayedItem("B", 1000));  // 1 second delay

// Retrieve elements in order of expiration
while (!queue.isEmpty()) {
    System.out.println(queue.take());  // "B" (1s) will be retrieved before "A" (2s)
}
```

In this example, even though item "A" was inserted before "B", the queue respects the delay time and "B" is retrieved first.


#### **Practical Example: Cache Expiry**

A common use case for `DelayQueue` is to automatically evict expired cache entries.

```java
class CacheItem implements Delayed {
    String key;
    Object value;
    long expiryTime;

    CacheItem(String key, Object value, long ttlMs) {
        this.key = key;
        this.value = value;
        this.expiryTime = System.nanoTime() + 
                         TimeUnit.NANOSECONDS.convert(ttlMs, TimeUnit.MILLISECONDS);
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return unit.convert(expiryTime - System.nanoTime(), TimeUnit.NANOSECONDS);
    }

    @Override
    public int compareTo(Delayed o) {
        return Long.compare(this.expiryTime, ((CacheItem) o).expiryTime);
    }
}
```

```java
public class ExpiringCache {
    private DelayQueue<CacheItem> queue = new DelayQueue<>();

    public void put(String key, Object value, long ttlMs) {
        queue.put(new CacheItem(key, value, ttlMs));
    }

    public void startCleanup() {
        new Thread(() -> {
            while (true) {
                try {
                    CacheItem expired = queue.take();  // Blocks until an item expires
                    System.out.println("Expired: " + expired.key);
                    // Remove from your actual cache (e.g., a Map), if applicable
                } catch (InterruptedException e) {
                    break;  // Gracefully exit on interruption
                }
            }
        }).start();
    }
}
```

This setup demonstrates how to use a `DelayQueue` to schedule automatic cleanup of cache entries based on their time-to-live (TTL).
{pagebreak}